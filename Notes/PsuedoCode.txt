Implementing an LFU (Least Frequently Used) cache eviction scheme with
 O(1) complexity for all operations requires a combination of data structures.
  Here's how you can achieve it:

    Hash Map: Use a hash map to store key-value pairs, where the keys are the
    cache keys, and the values are the corresponding cache entries.

    Doubly Linked List of Frequency Buckets: Maintain a doubly linked list where
     each node represents a frequency bucket. The nodes contain a frequency value
      and a linked list of cache entries with that frequency.

    Hash Map of Frequencies: Keep another hash map that maps each cache key to
    its corresponding frequency bucket node in the frequency list.

Here's how the algorithm works:

    When accessing or updating a key in the cache:
        If the key exists:
            Update the value.
            Increase the frequency of the corresponding cache entry.
            Move the cache entry to the next frequency bucket.
        If the key doesn't exist:
            If the cache is full, remove the least frequently used entry from the
            least frequent bucket.
            Create a new cache entry with the given key and value.
            Insert the new cache entry into the frequency bucket with frequency 1.
            Update the frequency map for the new cache entry.

    When removing the least frequently used entry:
        Traverse the frequency list from the head.
        Remove the first entry from the least frequent bucket.
        Update the frequency map accordingly.

This approach ensures that all operations (get, put, and remove) have O(1) time
complexity because each operation involves only constant-time operations on the hash
 maps and doubly linked lists.

 The proposed LFU (Least Frequently Used) algorithm presented in the paper achieves O(1)
  time complexity for all operations including insertion, lookup, and deletion (eviction).
   Here's a summary of the algorithm:

 1. **Use Cases**: LFU can be superior in scenarios where caching proxies need to maximize
  the amount of cached data in limited storage by evicting infrequently used resources.

 2. **Dictionary Operations**:
    - Set (Insert): O(1)
    - Retrieve (Lookup): O(1)
    - Evict (Delete): O(1)

 3. **Current Best-Known Complexity**:
    - Insert: O(log n)
    - Lookup: O(log n)
    - Delete: O(log n)
    The best-known LFU algorithm typically uses a min heap data structure and a hash map,
     resulting in logarithmic time complexity.

 4. **Proposed LFU Algorithm**:
    - Maintain two linked lists: one for access frequency and one for elements with the same
     frequency.
    - Use a hash table for key-based access to elements.
    - Each node in the frequency list represents a set of elements with the same access frequency.
    - Operations:
      - Insert: O(1) - Create a new node and add it to the appropriate frequency list.
      - Access: O(1) - Increment the access frequency of the element and move it to the next
       frequency list if needed.
      - Delete: O(1) - Remove the least frequently used element, adjusting the frequency list
      as necessary.

 5. **Implementation**:
    - Initialize LFU Cache: Create hash table for key-based access and an empty frequency list.
    - Access: Retrieve element by key, update its frequency, and move it to the appropriate
    frequency list.
    - Insert: Check if key exists, create a new node in the frequency list if needed, and add the
     element to the cache.
    - Evict: Remove least frequently used element from the cache.

 This algorithm ensures O(1) time complexity for all dictionary operations by efficiently
 maintaining frequency lists and using a hash table for key-based access. The proposed LFU
 algorithm provides a better alternative with constant-time complexity compared to the current
 best-known approach.

This implementation maintains a cache using a HashMap for key-based access and a HashMap of
 Sets for maintaining nodes with the same access frequency. The get method retrieves the value
  associated with a given key and updates the frequency of the accessed node. The put method
   inserts a new key-value pair into the cache, updating the frequency if the key already exists
    or evicting the least frequently used item if the cache is full.

The Node class represents a key-value pair along with its frequency of access. The evict method
 removes the least frequently used item from the cache, and the updateFrequency method adjusts
  the frequency of a node when it is accessed.

